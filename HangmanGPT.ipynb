{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[23318,   262, 17724,   286,   530,   286,   262,  1708,  7104,  3435,\n",
      "           357, 33469,   351, 44810,     8,   287,   262,  1708,  1573,  9086,\n",
      "           416,  3435,    25,   257,  4808,   257,   299,   288,  4808,   299,\n",
      "           304,   288,  1114,  1672,    11,   611,   262,  5128,  6827,   318,\n",
      "           705,    83,  4808,   300,   300,  4808,   374,  3256,   262,  7104,\n",
      "          3435,   389,   705,    64,     6,   290,   705,    68,     6,   764,\n",
      "           198,   198,   464,  1708,  1672,  2523,   703,   284,   779,   262,\n",
      "          7104,  3435,   287,   262,  1708,  6827,    25,   198,   198]])\n",
      "Predicted text: Give the prediction of one of the following hidden characters (represented with underscore) in the following word divided by characters: a _ a n d _ n e d For example, if the input sentence is 't _ l l _ r', the hidden characters are 'a' and 'e'.\n",
      "\n",
      "The following example shows how to use the hidden characters in the following sentence:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the pre-trained GPT model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Input sentence\n",
    "input_sentence = \"Give the prediction of one of the following hidden characters (represented with underscore) in the following word divided by characters: a _ a n d _ n e d\"\n",
    "\n",
    "input_sentence += \" For example, if the input sentence is 't _ l l _ r', the hidden characters are 'a' and 'e'\"\n",
    "\n",
    "# Tokenize input sentence\n",
    "inputs = tokenizer(input_sentence, return_tensors='pt')\n",
    "\n",
    "# Predict hidden characters\n",
    "outputs = model.generate(inputs['input_ids'], attention_mask = inputs['attention_mask'], max_length=inputs['input_ids'].shape[1] + 20, num_return_sequences=1)\n",
    "print(outputs)\n",
    "predicted_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "# Display the predicted character\n",
    "print(f\"Predicted text: {predicted_text}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "character-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
